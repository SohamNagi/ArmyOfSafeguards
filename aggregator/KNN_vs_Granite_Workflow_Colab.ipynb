{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN Aggregator vs IBM Granite-4.0-H-Tiny Workflow\n",
        "\n",
        "This notebook runs the complete workflow to compare KNN Aggregator with IBM Granite-4.0-H-Tiny model on benchmark datasets.\n",
        "\n",
        "## Workflow Steps:\n",
        "1. **Setup**: Install dependencies and setup project\n",
        "2. **Sampling**: Generate KNN reference data from HH-RLHF dataset\n",
        "3. **Evaluation**: Parallel evaluation of KNN Aggregator and IBM Granite on benchmark\n",
        "4. **Comparison**: Display performance metrics and improvements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q transformers>=4.44 torch scikit-learn datasets==3.6.0 huggingface_hub safetensors tqdm pandas numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Setup Project Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A: Clone from GitHub (if repository is public)\n",
        "!git clone https://github.com/SohamNagi/ArmyOfSafeguards.git\n",
        "%cd ArmyOfSafeguards\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: (Optional) Mount Google Drive for Persistent Storage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Optional: Copy project to Drive for persistence\n",
        "# !cp -r /content/ArmyOfSafeguards /content/drive/MyDrive/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Generate KNN Reference Data (Sampling)\n",
        "\n",
        "This step samples the HH-RLHF dataset and generates reference data for the KNN aggregator by running all 4 safeguards on the dataset.\n",
        "\n",
        "**Estimated time**: 10-30 minutes (with GPU), 1-3 hours (CPU only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate KNN reference data from HH-RLHF dataset\n",
        "# This will download the dataset and run all 4 safeguards (factuality, toxicity, sexual, jailbreak)\n",
        "!python aggregator/generate_knn_reference_hh_rlhf_full.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Compare KNN Aggregator vs IBM Granite-4.0-H-Tiny\n",
        "\n",
        "This step evaluates both models in parallel on the benchmark dataset and compares their performance.\n",
        "\n",
        "**Parameters**:\n",
        "- `--limit`: Number of examples to evaluate (default: 100)\n",
        "- `--threshold`: Confidence threshold for KNN aggregator (default: 0.7)\n",
        "- `--dataset`: Benchmark dataset to use (default: hh-rlhf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare KNN Aggregator vs IBM Granite on benchmark dataset\n",
        "# Adjust parameters as needed:\n",
        "#   --limit: Number of examples (default: 100)\n",
        "#   --threshold: Confidence threshold (default: 0.7)\n",
        "#   --dataset: Dataset name (default: hh-rlhf)\n",
        "\n",
        "!python aggregator/evaluate_vs_granite.py --dataset hh-rlhf --limit 100 --knn-reference aggregator/knn_reference_hh_rlhf_full.jsonl --threshold 0.7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: View Comparison Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Find the latest evaluation results\n",
        "result_files = list(Path(\"aggregator\").glob(\"evaluation_knn_vs_granite_*.json\"))\n",
        "if result_files:\n",
        "    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)\n",
        "    print(f\"Latest results: {latest_file}\")\n",
        "    \n",
        "    with open(latest_file) as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPARISON RESULTS: KNN Aggregator vs IBM Granite-4.0-H-Tiny\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    if \"knn_aggregator\" in results and \"ibm_granite\" in results:\n",
        "        knn = results[\"knn_aggregator\"]\n",
        "        granite = results[\"ibm_granite\"]\n",
        "        \n",
        "        print(\"\\nKNN Aggregator Performance:\")\n",
        "        print(f\"  Accuracy:  {knn.get('accuracy', 0):.2%}\")\n",
        "        print(f\"  Precision: {knn.get('precision', 0):.2%}\")\n",
        "        print(f\"  Recall:    {knn.get('recall', 0):.2%}\")\n",
        "        print(f\"  F1-Score:  {knn.get('f1_score', 0):.2%}\")\n",
        "        \n",
        "        print(\"\\nIBM Granite-4.0-H-Tiny Performance:\")\n",
        "        print(f\"  Accuracy:  {granite.get('accuracy', 0):.2%}\")\n",
        "        print(f\"  Precision: {granite.get('precision', 0):.2%}\")\n",
        "        print(f\"  Recall:    {granite.get('recall', 0):.2%}\")\n",
        "        print(f\"  F1-Score:  {granite.get('f1_score', 0):.2%}\")\n",
        "        \n",
        "        if \"improvement\" in results:\n",
        "            imp = results[\"improvement\"]\n",
        "            print(\"\\nPerformance Improvement (KNN vs Granite):\")\n",
        "            print(f\"  Accuracy:  {imp.get('accuracy', {}).get('percentage', 0):+.1f}% ({imp.get('accuracy', {}).get('absolute', 0):+.2%})\")\n",
        "            print(f\"  Precision: {imp.get('precision', {}).get('percentage', 0):+.1f}% ({imp.get('precision', {}).get('absolute', 0):+.2%})\")\n",
        "            print(f\"  Recall:    {imp.get('recall', {}).get('percentage', 0):+.1f}% ({imp.get('recall', {}).get('absolute', 0):+.2%})\")\n",
        "            print(f\"  F1-Score:  {imp.get('f1_score', {}).get('percentage', 0):+.1f}% ({imp.get('f1_score', {}).get('absolute', 0):+.2%})\")\n",
        "else:\n",
        "    print(\"No results found. Make sure Step 5 completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download evaluation results\n",
        "if result_files:\n",
        "    files.download(str(latest_file))\n",
        "    print(f\"✅ Downloaded: {latest_file}\")\n",
        "\n",
        "# Optionally download reference data\n",
        "# files.download(\"aggregator/knn_reference_hh_rlhf_full.jsonl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Workflow (All-in-One)\n",
        "\n",
        "Alternatively, you can use the workflow script to run everything in one command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the complete workflow in one command\n",
        "# This will generate reference data and compare KNN vs Granite\n",
        "!python aggregator/knn_workflow.py --limit 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips\n",
        "\n",
        "1. **Enable GPU**: Runtime → Change runtime type → GPU (for faster processing)\n",
        "2. **Skip generation**: If reference data already exists, you can skip Step 4\n",
        "3. **Adjust parameters**: Modify `--limit` and `--threshold` in Step 5 as needed\n",
        "4. **Save to Drive**: Mount Drive and copy results for persistence\n",
        "5. **Time limits**: Free Colab has session time limits (~12 hours)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
