{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXh4mlokmcoE"
      },
      "source": [
        "# KNN Aggregator vs IBM Granite-4.0-H-Tiny Workflow\n",
        "\n",
        "This notebook runs the complete workflow to compare KNN Aggregator with IBM Granite-4.0-H-Tiny model on benchmark datasets.\n",
        "\n",
        "## Workflow Steps:\n",
        "1. **Setup**: Install dependencies and setup project\n",
        "2. **Sampling**: Generate KNN reference data from HH-RLHF dataset\n",
        "3. **Evaluation**: Parallel evaluation of KNN Aggregator and IBM Granite on benchmark\n",
        "4. **Comparison**: Display performance metrics and improvements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw4DWDU1mcoG"
      },
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYBt5cS3mcoG"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q transformers>=4.44 torch scikit-learn datasets==3.6.0 huggingface_hub safetensors tqdm pandas numpy\n",
        "\n",
        "# Verify installation\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(\"‚úÖ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaolePV0mcoI"
      },
      "source": [
        "## Step 2: Setup Project Files\n",
        "\n",
        "**Note**: The notebook will automatically checkout the `experimental-knn` branch which contains all KNN files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keAXTRZRmcoI",
        "outputId": "49309012-5c86-4e9d-9a98-e616b0507e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository 'ArmyOfSafeguards' already exists. Skipping clone.\n",
            "M\taggregator/knn_reference_hh_rlhf_full.checkpoint.json\n",
            "Already on 'experimental-knn'\n",
            "Your branch is up to date with 'origin/experimental-knn'.\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 765 bytes | 69.00 KiB/s, done.\n",
            "From https://github.com/SohamNagi/ArmyOfSafeguards\n",
            "   573aebe..5eece91  experimental-knn -> origin/experimental-knn\n",
            "Updating 573aebe..5eece91\n",
            "Fast-forward\n",
            " aggregator/evaluate_vs_granite.py | 25 \u001b[32m+++++++++++++++++++++\u001b[m\u001b[31m----\u001b[m\n",
            " 1 file changed, 21 insertions(+), 4 deletions(-)\n",
            "‚úÖ Project files set up in: /content/ArmyOfSafeguards\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ensure we are in the /content directory before cloning\n",
        "# This is important for consistent project structure\n",
        "os.chdir('/content')\n",
        "\n",
        "# Clone the repository if it doesn't already exist\n",
        "repo_name = \"ArmyOfSafeguards\"\n",
        "if not os.path.exists(repo_name):\n",
        "    !git clone https://github.com/SohamNagi/ArmyOfSafeguards.git\n",
        "else:\n",
        "    print(f\"Repository '{repo_name}' already exists. Skipping clone.\")\n",
        "\n",
        "# Change into the repository directory to perform checkout\n",
        "os.chdir(repo_name)\n",
        "\n",
        "# Checkout the experimental-knn branch\n",
        "!git checkout experimental-knn\n",
        "!git pull\n",
        "# The working directory is now /content/ArmyOfSafeguards, which is where subsequent scripts expect the 'aggregator' directory to be.\n",
        "print(f\"‚úÖ Project files set up in: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fILGXDpHmcoJ"
      },
      "source": [
        "## Step 3: Generate KNN Reference Data (Sampling)\n",
        "\n",
        "This step samples the HH-RLHF dataset and generates reference data for the KNN aggregator by running all 4 safeguards on the dataset.\n",
        "\n",
        "**Note**: Reference data files are saved to the current working directory (`/content/ArmyOfSafeguards/`), not in the `aggregator/` subdirectory. You can use all available processed data even if generation is interrupted - the script will resume from the last checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm7U4TnCmcoJ",
        "outputId": "c96723df-4699-4827-ae21-d45ad4c30449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found script: aggregator/generate_knn_reference_hh_rlhf_full.py\n",
            "Current directory: /content/ArmyOfSafeguards\n",
            "Loading Anthropic/hh-rlhf dataset (subset='harmless-base', split='train')...\n",
            "Processing 42537 prompt pairs (~85074 responses) with batch size 64.\n",
            "üîÅ Resuming from checkpoint at /content/ArmyOfSafeguards/aggregator/knn_reference_hh_rlhf_full.checkpoint.json\n",
            "Chosen responses (safe):   0% 0/42039 [00:00<?, ?it/s]2025-11-27 15:46:28.452515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764258388.495280   14458 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764258388.509486   14458 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764258388.555804   14458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764258388.555904   14458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764258388.555918   14458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764258388.555922   14458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-27 15:46:28.569204: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Chosen responses (safe):  11% 4432/42039 [4:06:02<34:47:45,  3.33s/it]\n",
            "\n",
            "üõë Interrupted while processing Chosen responses (safe).\n",
            "üíæ Checkpoint saved ‚Üí /content/ArmyOfSafeguards/aggregator/knn_reference_hh_rlhf_full.checkpoint.json (chosen=4930, rejected=0)\n",
            "Progress saved. Re-run the script to resume from the last checkpoint.\n",
            "üíæ Checkpoint saved ‚Üí /content/ArmyOfSafeguards/aggregator/knn_reference_hh_rlhf_full.checkpoint.json (chosen=4930, rejected=0)\n",
            "‚û°Ô∏è  Partial progress stored in /content/ArmyOfSafeguards/aggregator/knn_reference_hh_rlhf_full.checkpoint.json\n",
            "\n",
            "============================================================\n",
            "KNN Data Generation Paused\n",
            "============================================================\n",
            "Reference data file: /content/ArmyOfSafeguards/aggregator/knn_reference_hh_rlhf_full.jsonl\n",
            "\n",
            "To load the reference data, use:\n",
            "  from aggregator.aggregator import load_knn_reference_data\n",
            "  load_knn_reference_data('/content/ArmyOfSafeguards/aggregator/knn_reference_hh_rlhf_full.jsonl')\n",
            "Exception ignored in: <function Dataset.__del__ at 0x791a8da1ede0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\", line 1413, in __del__\n",
            "    if hasattr(self, \"_indices\"):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "# Generate KNN reference data from HH-RLHF dataset\n",
        "# This will download the dataset and run all 4 safeguards (factuality, toxicity, sexual, jailbreak)\n",
        "\n",
        "import os\n",
        "\n",
        "# Make sure we're in the right directory\n",
        "if not os.path.exists(\"aggregator\"):\n",
        "    print(\"‚ùå Error: aggregator directory not found!\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "    print(\"Please run Step 2 first to setup project files.\")\n",
        "    raise FileNotFoundError(\"aggregator directory not found\")\n",
        "\n",
        "script_path = \"aggregator/generate_knn_reference_hh_rlhf_full.py\"\n",
        "if os.path.exists(script_path):\n",
        "    print(f\"‚úÖ Found script: {script_path}\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "    !python aggregator/generate_knn_reference_hh_rlhf_full.py\n",
        "else:\n",
        "    print(f\"‚ùå Script not found: {script_path}\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "    print(f\"Files in current directory: {os.listdir('.')}\")\n",
        "    if os.path.exists(\"aggregator\"):\n",
        "        print(f\"Files in aggregator/: {os.listdir('aggregator')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCu9jSe5mcoJ"
      },
      "source": [
        "## Step 4: Compare KNN Aggregator vs IBM Granite-4.0-H-Tiny\n",
        "\n",
        "This step evaluates both models in parallel on the benchmark dataset and compares their performance.\n",
        "\n",
        "**Parameters**:\n",
        "- `--limit`: Number of examples to evaluate (default: 100)\n",
        "- `--threshold`: Confidence threshold for KNN aggregator (default: 0.7)\n",
        "- `--dataset`: Benchmark dataset to use (default: hh-rlhf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8PU8NZzAYQC",
        "outputId": "5bb0b2fd-6bb1-4ce5-cc50-2ad6de34283d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zDfu6v3mcoJ",
        "outputId": "504234ae-ac16-4cf6-ce66-7ab03b446026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found script: aggregator/evaluate_vs_granite.py\n",
            "‚úÖ Found reference data: aggregator/knn_reference_hh_rlhf_full.jsonl\n",
            "Current directory: /content/ArmyOfSafeguards\n",
            "\n",
            "============================================================\n",
            "COMPARING KNN AGGREGATOR vs IBM GRANITE-4.0-H-TINY\n",
            "============================================================\n",
            "\n",
            "[1/3] Loading KNN reference data from: aggregator/knn_reference_hh_rlhf_full.jsonl\n",
            "[KNN] Fitted with 4930 reference samples, k=7\n",
            "[KNN] Loaded 4930 reference samples\n",
            "‚úÖ KNN reference data loaded\n",
            "\n",
            "[2/3] Loading IBM Granite model...\n",
            "Loading IBM Granite model: ibm-granite/granite-4.0-h-tiny\n",
            "‚ö†Ô∏è  Using CPU for Granite model (slower)\n",
            "Loading model shards (this may take a moment)...\n",
            "2025-11-27 20:28:30.819825: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764275311.008909   81871 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764275311.061002   81871 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764275311.415442   81871 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764275311.415488   81871 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764275311.415493   81871 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764275311.415500   81871 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-27 20:28:31.475851: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards:  33% 1/3 [00:23<00:46, 23.11s/it]^C\n"
          ]
        }
      ],
      "source": [
        "# Compare KNN Aggregator vs IBM Granite on benchmark dataset\n",
        "# Adjust parameters as needed:\n",
        "#   --limit: Number of examples (default: 100)\n",
        "#   --threshold: Confidence threshold (default: 0.7)\n",
        "#   --dataset: Dataset name (default: hh-rlhf)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Make sure we're in the right directory\n",
        "if not os.path.exists(\"aggregator\"):\n",
        "    print(\"‚ùå Error: aggregator directory not found!\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "    print(\"Please run Step 2 first to setup project files.\")\n",
        "    raise FileNotFoundError(\"aggregator directory not found\")\n",
        "\n",
        "script_path = \"aggregator/evaluate_vs_granite.py\"\n",
        "\n",
        "# Check for reference data in current directory first (new location), then aggregator/ (old location)\n",
        "ref_path_current = \"knn_reference_hh_rlhf_full.jsonl\"\n",
        "ref_path_old = \"aggregator/knn_reference_hh_rlhf_full.jsonl\"\n",
        "\n",
        "if os.path.exists(ref_path_current):\n",
        "    ref_path = ref_path_current\n",
        "    print(f\"‚úÖ Found reference data in current directory: {ref_path}\")\n",
        "elif os.path.exists(ref_path_old):\n",
        "    ref_path = ref_path_old\n",
        "    print(f\"‚úÖ Found reference data in aggregator/ (legacy location): {ref_path}\")\n",
        "else:\n",
        "    ref_path = None\n",
        "    print(f\"‚ö†Ô∏è  Reference data not found in current directory or aggregator/\")\n",
        "    print(f\"   Checked: {os.path.abspath(ref_path_current)}\")\n",
        "    print(f\"   Checked: {os.path.abspath(ref_path_old)}\")\n",
        "    print(\"Please run Step 3 first to generate reference data.\")\n",
        "\n",
        "if os.path.exists(script_path):\n",
        "    if ref_path and os.path.exists(ref_path):\n",
        "        print(f\"‚úÖ Found script: {script_path}\")\n",
        "        print(f\"Current directory: {os.getcwd()}\")\n",
        "        !python aggregator/evaluate_vs_granite.py --dataset hh-rlhf --limit 100 --knn-reference {ref_path} --threshold 0.7\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Reference data not found. Please run Step 3 first to generate reference data.\")\n",
        "else:\n",
        "    print(f\"‚ùå Script not found: {script_path}\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T8JGWWgmcoJ"
      },
      "source": [
        "## Step 5: View Comparison Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFjJFUCgmcoK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Find the latest evaluation results (check both current directory and aggregator/)\n",
        "result_files = list(Path(\".\").glob(\"evaluation_knn_vs_granite_*.json\"))\n",
        "result_files.extend(Path(\"aggregator\").glob(\"evaluation_knn_vs_granite_*.json\"))\n",
        "if result_files:\n",
        "    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)\n",
        "    print(f\"Latest results: {latest_file}\")\n",
        "\n",
        "    with open(latest_file) as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPARISON RESULTS: KNN Aggregator vs IBM Granite-4.0-H-Tiny\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if \"knn_aggregator\" in results and \"ibm_granite\" in results:\n",
        "        knn = results[\"knn_aggregator\"]\n",
        "        granite = results[\"ibm_granite\"]\n",
        "\n",
        "        print(\"\\nKNN Aggregator Performance:\")\n",
        "        print(f\"  Accuracy:  {knn.get('accuracy', 0):.2%}\")\n",
        "        print(f\"  Precision: {knn.get('precision', 0):.2%}\")\n",
        "        print(f\"  Recall:    {knn.get('recall', 0):.2%}\")\n",
        "        print(f\"  F1-Score:  {knn.get('f1_score', 0):.2%}\")\n",
        "\n",
        "        print(\"\\nIBM Granite-4.0-H-Tiny Performance:\")\n",
        "        print(f\"  Accuracy:  {granite.get('accuracy', 0):.2%}\")\n",
        "        print(f\"  Precision: {granite.get('precision', 0):.2%}\")\n",
        "        print(f\"  Recall:    {granite.get('recall', 0):.2%}\")\n",
        "        print(f\"  F1-Score:  {granite.get('f1_score', 0):.2%}\")\n",
        "\n",
        "        if \"improvement\" in results:\n",
        "            imp = results[\"improvement\"]\n",
        "            print(\"\\nPerformance Improvement (KNN vs Granite):\")\n",
        "            print(f\"  Accuracy:  {imp.get('accuracy', {}).get('percentage', 0):+.1f}% ({imp.get('accuracy', {}).get('absolute', 0):+.2%})\")\n",
        "            print(f\"  Precision: {imp.get('precision', {}).get('percentage', 0):+.1f}% ({imp.get('precision', {}).get('absolute', 0):+.2%})\")\n",
        "            print(f\"  Recall:    {imp.get('recall', {}).get('percentage', 0):+.1f}% ({imp.get('recall', {}).get('absolute', 0):+.2%})\")\n",
        "            print(f\"  F1-Score:  {imp.get('f1_score', {}).get('percentage', 0):+.1f}% ({imp.get('f1_score', {}).get('absolute', 0):+.2%})\")\n",
        "else:\n",
        "    print(\"No results found. Make sure Step 5 completed successfully.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
